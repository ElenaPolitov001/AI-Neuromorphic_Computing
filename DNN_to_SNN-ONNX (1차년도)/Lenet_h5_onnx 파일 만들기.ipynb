{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Lenet-1 Model and Convert ONNX\n",
    "- Keras로 Lenet-1 모델 생성 \n",
    "- 학습은 Mnist Data로 진행\n",
    "- <b> .h5 모델 로드 후 .onnx로 변환 </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--images are being resizing--\n",
      "--image resize complete--\n",
      "--images are being resizing--\n",
      "--image resize complete--\n",
      "data resize  (60000, 28, 28) (10000, 28, 28)\n",
      "expand_dims  (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "to_categorical  (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "전처리 작업 완료\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import utils\n",
    "from PIL import Image\n",
    "\n",
    "# image resize 함수\n",
    "def img_resize(value, img_array):\n",
    "    print(\"--images are being resizing--\")\n",
    "    result = np.zeros((len(img_array), value[0], value[1]))\n",
    "\n",
    "    for index in range(len(img_array)):\n",
    "        img = Image.fromarray(img_array[index], 'L')\n",
    "        img = img.resize((value[0], value[1]))\n",
    "        img = np.array(img)\n",
    "        result[index] = img\n",
    "    print(\"--image resize complete--\")\n",
    "    return result\n",
    "\n",
    "# mnist Data Load 및\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "classes=10\n",
    "input_shape = (28, 28)\n",
    "\n",
    "# data resize\n",
    "X_train = img_resize(input_shape, X_train)\n",
    "X_test = img_resize(input_shape, X_test)\n",
    "print('data resize ',X_train.shape, X_test.shape)\n",
    "\n",
    "# 차원 확장\n",
    "X_train = np.expand_dims(X_train, axis = -1)\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "print('expand_dims ',X_train.shape, X_test.shape)\n",
    "\n",
    "# 정답값 categorical로\n",
    "Y_train = utils.to_categorical(Y_train, 10)\n",
    "Y_test = utils.to_categorical(Y_test, 10)\n",
    "print('to_categorical ',X_train.shape, X_test.shape)\n",
    "\n",
    "print('전처리 작업 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 2.0821 - accuracy: 0.3179 - val_loss: 1.8772 - val_accuracy: 0.4796\n",
      "10000/10000 [==============================] - 2s 180us/step\n",
      "prediction_acc:  0.4796000123023987\n",
      "prediction_loss:  1.877234927368164\n",
      "저장완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장 경로\n",
    "MODEL_SAVE_FOLDER_PATH = 'model/'\n",
    "\n",
    "# Lenet 모델 만듬\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape = (input_shape[0], input_shape[1], 1), filters = 4, kernel_size = (5, 5), strides=(1, 1), padding = 'same', name = 'conv1'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), name = 'avgpool1'))\n",
    "\n",
    "model.add(Conv2D(filters = 12, kernel_size = (5, 5), strides=(1, 1), padding = 'valid', name = 'conv2'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), name = 'avgpool2'))\n",
    "\n",
    "model.add(Flatten(name = 'flatten'))\n",
    "\n",
    "model.add(Dense(classes, activation = 'softmax',  name = 'predictions'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    validation_data = (X_test, Y_test),\n",
    "                    epochs = 1, batch_size = 1000, verbose = 1)\n",
    "\n",
    "# 모델 save .h5 파일\n",
    "model.save(MODEL_SAVE_FOLDER_PATH + \"lenet-1.h5\")\n",
    "print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx로 변환 완료\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras2onnx import convert_keras\n",
    "model = load_model('model/lenet-1.h5')\n",
    "\n",
    "# keras model -> onnx 로 변환\n",
    "onx = convert_keras(model, 'lenet-1.onnx')\n",
    "\n",
    "with open(\"model/lenet-1.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n",
    "\n",
    "print('onnx로 변환 완료')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
